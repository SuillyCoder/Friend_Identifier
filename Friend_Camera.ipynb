{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5ad9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0e16982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Directory for OpenCV screenshots\n",
    "screenshot_dir = 'CV_Screenshots'\n",
    "os.makedirs(screenshot_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a08de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PHASE 1: CAMERA ACCESS AND SETUP\n",
    "\n",
    "def find_working_camera():\n",
    "    print(\"ğŸ” Searching for working camera...\\n\")\n",
    "    \n",
    "    # Try with AVFoundation (Mac-specific)\n",
    "    cap = cv2.VideoCapture(1, cv2.CAP_AVFOUNDATION)\n",
    "        \n",
    "    if cap.isOpened():\n",
    "            # Try to read a frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret and frame is not None:\n",
    "            h, w = frame.shape[:2]\n",
    "            print(f\"âœ… WORKS! ({w}x{h})\")\n",
    "            cap.release()\n",
    "            return 1\n",
    "        else:\n",
    "            print(\"âŒ Opens but can't grab frames\")\n",
    "    else:\n",
    "        print(\"âŒ Can't open\")\n",
    "        \n",
    "    cap.release()\n",
    "    \n",
    "    return None\n",
    "\n",
    "def test_camera_access():\n",
    "    # Find working camera\n",
    "    camera_index = find_working_camera()\n",
    "    \n",
    "    if camera_index is None:\n",
    "        print(\"\\nâŒ ERROR: No working camera found!\")\n",
    "        print(\"ğŸ’¡ Troubleshooting:\")\n",
    "        print(\"   1. Close any apps using camera (Zoom, Teams, FaceTime)\")\n",
    "        print(\"   2. System Settings > Privacy & Security > Camera\")\n",
    "        print(\"      â†’ Enable for Terminal/Python/VS Code\")\n",
    "        print(\"   3. Restart your Python kernel/terminal\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nâœ… Using camera {camera_index}\")\n",
    "    \n",
    "    # Open camera with AVFoundation backend (better for Mac)\n",
    "    cap = cv2.VideoCapture(camera_index, cv2.CAP_AVFOUNDATION)\n",
    "    \n",
    "    # Force better settings\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "    \n",
    "    print(\"âœ… Camera opened successfully!\")\n",
    "    print(\"\\nğŸ“‹ Instructions:\")\n",
    "    print(\"   - Press 'q' to quit\")\n",
    "    print(\"   - Press 's' to save screenshot\")\n",
    "    print(\"   - ESC also quits\")\n",
    "    print(\"\\nCamera window should open now...\\n\")\n",
    "    \n",
    "    # Get camera properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    print(f\"ğŸ“Š Camera Info:\")\n",
    "    print(f\"   Resolution: {width}x{height}\")\n",
    "    print(f\"   FPS: {fps}\")\n",
    "    \n",
    "    screenshot_count = 0\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Main camera loop\n",
    "    while True:\n",
    "        # Read frame from camera\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"âŒ Failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Calculate actual FPS\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > 0:\n",
    "            actual_fps = frame_count / elapsed_time\n",
    "        else:\n",
    "            actual_fps = 0\n",
    "        \n",
    "        # Add FPS counter to frame\n",
    "        cv2.putText(\n",
    "            frame, \n",
    "            f\"FPS: {actual_fps:.1f}\", \n",
    "            (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            0.7, \n",
    "            (0, 255, 0), \n",
    "            2\n",
    "        )\n",
    "        \n",
    "        # Add instructions\n",
    "        cv2.putText(\n",
    "            frame, \n",
    "            \"Press 'q' to quit, 's' for screenshot\", \n",
    "            (10, height - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            0.5, \n",
    "            (255, 255, 255), \n",
    "            1\n",
    "        )\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('Friend Classifier - Phase 1', frame)\n",
    "        \n",
    "        # Handle keyboard input\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q') or key == 27:  # 'q' or ESC\n",
    "            print(\"\\nğŸ‘‹ Quitting...\")\n",
    "            break\n",
    "        elif key == ord('s'):  # Save screenshot\n",
    "            screenshot_count += 1\n",
    "            filename = os.path.join(screenshot_dir, f'screenshot_{screenshot_count}.jpg')\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"ğŸ“¸ Screenshot saved: {filename}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7236b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 2: FACE DETECTION\n",
    "\n",
    "def load_face_detector():    \n",
    "    cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "    face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "    \n",
    "    if face_cascade.empty():\n",
    "        print(\"âŒ ERROR: Could not load face detector!\")\n",
    "        print(f\"   Tried path: {cascade_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(\"âœ… Face detector loaded successfully!\")\n",
    "    return face_cascade\n",
    "\n",
    "\n",
    "def detect_faces(frame, face_cascade, scale_factor=1.1, min_neighbors=5, min_size=(30, 30)):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=scale_factor,\n",
    "        minNeighbors=min_neighbors,\n",
    "        minSize=min_size,\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9046476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 3: FACE PREPROCESSING\n",
    "\n",
    "def create_output_folder(folder_name=\"CV_PrePrep_Faces\"):\n",
    "    folder_path = Path(folder_name)\n",
    "    folder_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"ğŸ“ Output folder ready: {folder_path.absolute()}\")\n",
    "    \n",
    "    return folder_path\n",
    "\n",
    "\n",
    "def crop_face(frame, face_coords, margin=20): \n",
    "    x, y, w, h = face_coords\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    \n",
    "    # Add margin but stay within frame bounds\n",
    "    x1 = max(0, x - margin)\n",
    "    y1 = max(0, y - margin)\n",
    "    x2 = min(frame_width, x + w + margin)\n",
    "    y2 = min(frame_height, y + h + margin)\n",
    "    \n",
    "    # Crop the face\n",
    "    face_crop = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    actual_coords = (x1, y1, x2-x1, y2-y1)\n",
    "    \n",
    "    return face_crop, actual_coords\n",
    "\n",
    "\n",
    "def preprocess_face_for_model(face_crop, target_size=(128, 128), normalize=True):\n",
    "    # Step 1: Convert BGR to RGB (OpenCV uses BGR, model expects RGB)\n",
    "    face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Step 2: Resize to model's expected input size\n",
    "    face_resized = cv2.resize(face_rgb, target_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Step 3: Create display version (before normalization)\n",
    "    display_face = face_resized.copy()\n",
    "    \n",
    "    # Step 4: Normalize pixel values to 0-1 range (if needed)\n",
    "    if normalize:\n",
    "        face_normalized = face_resized.astype(np.float32) / 255.0\n",
    "    else:\n",
    "        face_normalized = face_resized.astype(np.float32)\n",
    "    \n",
    "    # Step 5: Add batch dimension (model expects: batch_size, height, width, channels)\n",
    "    face_batched = np.expand_dims(face_normalized, axis=0)\n",
    "    \n",
    "    return face_batched, display_face\n",
    "\n",
    "\n",
    "def save_preprocessed_face(face_image, folder_path, prefix=\"face\", timestamp=None):\n",
    "    if timestamp is None:\n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Generate unique filename\n",
    "    filename = folder_path / f\"{prefix}_{timestamp}.jpg\"\n",
    "    \n",
    "    # Convert RGB to BGR for saving (OpenCV saves in BGR)\n",
    "    if face_image.dtype == np.float32:\n",
    "        # If normalized, denormalize first\n",
    "        face_image = (face_image * 255).astype(np.uint8)\n",
    "    \n",
    "    face_bgr = cv2.cvtColor(face_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Save\n",
    "    cv2.imwrite(str(filename), face_bgr)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "\n",
    "def visualize_preprocessing_pipeline(face_crop, target_size=(128, 128)):\n",
    "    # Original (BGR)\n",
    "    step1 = face_crop\n",
    "    \n",
    "    # Convert to RGB\n",
    "    step2 = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize\n",
    "    step3 = cv2.resize(step2, target_size)\n",
    "    \n",
    "    # Normalize (for visualization, convert back to 0-255)\n",
    "    step4_normalized = step3.astype(np.float32) / 255.0\n",
    "    step4 = (step4_normalized * 255).astype(np.uint8)\n",
    "    \n",
    "    # Create visualization\n",
    "    h, w = 200, 200\n",
    "    \n",
    "    # Resize all to same size for display\n",
    "    display1 = cv2.resize(step1, (w, h))\n",
    "    display2 = cv2.resize(cv2.cvtColor(step2, cv2.COLOR_RGB2BGR), (w, h))\n",
    "    display3 = cv2.resize(cv2.cvtColor(step3, cv2.COLOR_RGB2BGR), (w, h))\n",
    "    display4 = cv2.resize(cv2.cvtColor(step4, cv2.COLOR_RGB2BGR), (w, h))\n",
    "    \n",
    "    # Add labels\n",
    "    def add_label(img, text):\n",
    "        labeled = img.copy()\n",
    "        cv2.putText(labeled, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   0.7, (0, 255, 0), 2)\n",
    "        return labeled\n",
    "    \n",
    "    display1 = add_label(display1, \"1. Original\")\n",
    "    display2 = add_label(display2, \"2. BGR->RGB\")\n",
    "    display3 = add_label(display3, f\"3. Resize {target_size}\")\n",
    "    display4 = add_label(display4, \"4. Normalized\")\n",
    "    \n",
    "    # Combine horizontally\n",
    "    top_row = np.hstack([display1, display2])\n",
    "    bottom_row = np.hstack([display3, display4])\n",
    "    combined = np.vstack([top_row, bottom_row])\n",
    "    \n",
    "    return combined\n",
    "\n",
    "# MAIN DEMO FUNCTION\n",
    "def face_preprocessing_demo(camera_index=1):\n",
    "    # Setup\n",
    "    face_cascade = load_face_detector()\n",
    "    if face_cascade is None:\n",
    "        return\n",
    "    \n",
    "    output_folder = create_output_folder(\"CV_PrePrep_Faces\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(camera_index, cv2.CAP_AVFOUNDATION)\n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ Failed to open camera\")\n",
    "        return\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Controls:\")\n",
    "    print(\"   q - Quit\")\n",
    "    print(\"   s - Save preprocessed face\")\n",
    "    print(\"   v - Visualize preprocessing steps\")\n",
    "    print(\"   d - Toggle debug info\")\n",
    "    print(\"\\nWindow opening...\\n\")\n",
    "    \n",
    "    # State\n",
    "    show_debug = True\n",
    "    saved_count = 0\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = detect_faces(frame, face_cascade)\n",
    "        \n",
    "        # Process each detected face\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            # Draw detection box\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Crop face\n",
    "            face_crop, _ = crop_face(frame, (x, y, w, h), margin=20)\n",
    "            \n",
    "            if face_crop.size == 0:\n",
    "                continue\n",
    "            \n",
    "            # Preprocess for model\n",
    "            face_processed, face_display = preprocess_face_for_model(\n",
    "                face_crop, \n",
    "                target_size=(128, 128)\n",
    "            )\n",
    "            \n",
    "            # Display preprocessed face in corner\n",
    "            corner_size = 150\n",
    "            face_corner = cv2.resize(\n",
    "                cv2.cvtColor(face_display, cv2.COLOR_RGB2BGR),\n",
    "                (corner_size, corner_size)\n",
    "            )\n",
    "            \n",
    "            # Position in top-right corner\n",
    "            frame[10:10+corner_size, frame.shape[1]-corner_size-10:frame.shape[1]-10] = face_corner\n",
    "            \n",
    "            # Add border around preview\n",
    "            cv2.rectangle(\n",
    "                frame,\n",
    "                (frame.shape[1]-corner_size-10, 10),\n",
    "                (frame.shape[1]-10, 10+corner_size),\n",
    "                (255, 255, 0),\n",
    "                2\n",
    "            )\n",
    "            \n",
    "            # Show preprocessing info\n",
    "            if show_debug:\n",
    "                info_x = x\n",
    "                info_y = y - 10\n",
    "                \n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    f\"Face {i+1}\",\n",
    "                    (info_x, info_y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6,\n",
    "                    (0, 255, 0),\n",
    "                    2\n",
    "                )\n",
    "                \n",
    "                # Show dimensions\n",
    "                debug_text = [\n",
    "                    f\"Original: {face_crop.shape[1]}x{face_crop.shape[0]}\",\n",
    "                    f\"Processed: 128x128\",\n",
    "                    f\"Shape: {face_processed.shape}\",\n",
    "                    f\"Range: [0.0, 1.0]\"\n",
    "                ]\n",
    "                \n",
    "                for j, text in enumerate(debug_text):\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        text,\n",
    "                        (info_x, y + h + 20 + j*20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.4,\n",
    "                        (255, 255, 255),\n",
    "                        1\n",
    "                    )\n",
    "        \n",
    "        # Add overlay info\n",
    "        fps = frame_count / (time.time() - start_time)\n",
    "        \n",
    "        cv2.putText(frame, f\"FPS: {fps:.1f}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame, f\"Faces: {len(faces)}\", (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame, f\"Saved: {saved_count}\", (10, 90),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame, \"Preview (preprocessed)\", \n",
    "                   (frame.shape[1]-240, frame.shape[0]-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)\n",
    "        \n",
    "        cv2.putText(frame, \"q: Quit | s: Save | v: Visualize | d: Debug\",\n",
    "                   (10, frame.shape[0]-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Display\n",
    "        cv2.imshow('Phase 2+3: Detection & Preprocessing', frame)\n",
    "        \n",
    "        # Handle input\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        \n",
    "        elif key == ord('s') and len(faces) > 0:\n",
    "            # Save first detected face\n",
    "            face_crop, _ = crop_face(frame, faces[0], margin=20)\n",
    "            _, face_display = preprocess_face_for_model(face_crop)\n",
    "            \n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S_%f\")[:-3]\n",
    "            filename = save_preprocessed_face(face_display, output_folder, timestamp=timestamp)\n",
    "            \n",
    "            saved_count += 1\n",
    "            print(f\"ğŸ’¾ Saved: {filename}\")\n",
    "        \n",
    "        elif key == ord('v') and len(faces) > 0:\n",
    "            # Show preprocessing visualization\n",
    "            face_crop, _ = crop_face(frame, faces[0], margin=20)\n",
    "            vis = visualize_preprocessing_pipeline(face_crop)\n",
    "            \n",
    "            cv2.imshow('Preprocessing Steps', vis)\n",
    "            print(\"ğŸ“Š Preprocessing visualization opened (close window to continue)\")\n",
    "        \n",
    "        elif key == ord('d'):\n",
    "            show_debug = not show_debug\n",
    "            print(f\"ğŸ› Debug info: {'ON' if show_debug else 'OFF'}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ab8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 4: MODEL LOADING AND PREDICTION\n",
    "\n",
    "def load_trained_model(model_path=\"Models/friend_classifier_v2.keras\"):\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸ”„ Loading model from {model_path}...\")\n",
    "        model = keras.models.load_model(model_path)\n",
    "        print(\"âœ… Model loaded successfully!\")\n",
    "        \n",
    "        # Print model summary\n",
    "        print(\"\\nğŸ“Š Model Summary:\")\n",
    "        print(f\"   Input shape: {model.input_shape}\")\n",
    "        print(f\"   Output shape: {model.output_shape}\")\n",
    "        print(f\"   Total parameters: {model.count_params():,}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ERROR loading model: {e}\")\n",
    "        print(f\"   Make sure '{model_path}' exists in the current directory\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def predict_friend(model, face_processed, class_names, confidence_threshold=0.3):\n",
    "    try:\n",
    "        # Make prediction\n",
    "        predictions = model.predict(face_processed, verbose=0)\n",
    "        \n",
    "        # Get predicted class and confidence\n",
    "        predicted_class_idx = np.argmax(predictions[0])\n",
    "        confidence = predictions[0][predicted_class_idx]\n",
    "        \n",
    "        # Get predicted name\n",
    "        predicted_name = class_names[predicted_class_idx]\n",
    "        \n",
    "        # Create dictionary of all predictions\n",
    "        all_predictions = {\n",
    "            class_names[i]: float(predictions[0][i]) \n",
    "            for i in range(len(class_names))\n",
    "        }\n",
    "        \n",
    "        # If confidence is too low, return \"Unknown\"\n",
    "        if confidence < confidence_threshold:\n",
    "            predicted_name = \"Unknown\"\n",
    "        \n",
    "        return predicted_name, float(confidence), all_predictions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Prediction error: {e}\")\n",
    "        return \"Error\", 0.0, {}\n",
    "\n",
    "\n",
    "def draw_prediction_box(frame, face_coords, name, confidence, color=None):\n",
    "    x, y, w, h = face_coords\n",
    "    \n",
    "    # Color coding based on confidence\n",
    "    if color is None:\n",
    "        if confidence >= 0.7:\n",
    "            color = (0, 255, 0)  # Green - High confidence\n",
    "        elif confidence >= 0.5:\n",
    "            color = (0, 255, 255)  # Yellow - Medium confidence\n",
    "        elif confidence >= 0.3:\n",
    "            color = (0, 165, 255)  # Orange - Low confidence\n",
    "        else:\n",
    "            color = (0, 0, 255)  # Red - Very low confidence\n",
    "    \n",
    "    # Draw rectangle\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), color, 3)\n",
    "    \n",
    "    # Prepare label\n",
    "    label = f\"{name} ({confidence*100:.1f}%)\"\n",
    "    \n",
    "    # Calculate label background size\n",
    "    (label_w, label_h), baseline = cv2.getTextSize(\n",
    "        label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2\n",
    "    )\n",
    "    \n",
    "    # Draw label background\n",
    "    cv2.rectangle(\n",
    "        frame,\n",
    "        (x, y - label_h - 15),\n",
    "        (x + label_w + 10, y),\n",
    "        color,\n",
    "        -1  # Filled\n",
    "    )\n",
    "    \n",
    "    # Draw label text\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        label,\n",
    "        (x + 5, y - 8),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (255, 255, 255),  # White text\n",
    "        2\n",
    "    )\n",
    "\n",
    "\n",
    "def display_top_predictions(frame, all_predictions, x_offset=10, y_offset=120):\n",
    "    # Sort predictions by confidence\n",
    "    sorted_preds = sorted(all_predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Draw title\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        \"Top Predictions:\",\n",
    "        (x_offset, y_offset),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.6,\n",
    "        (255, 255, 255),\n",
    "        2\n",
    "    )\n",
    "    \n",
    "    # Draw top 3\n",
    "    for i, (name, conf) in enumerate(sorted_preds[:3]):\n",
    "        y_pos = y_offset + 30 + (i * 25)\n",
    "        text = f\"{i+1}. {name}: {conf*100:.1f}%\"\n",
    "        \n",
    "        # Color based on rank\n",
    "        if i == 0:\n",
    "            color = (0, 255, 0)  # Green\n",
    "        elif i == 1:\n",
    "            color = (0, 255, 255)  # Yellow\n",
    "        else:\n",
    "            color = (255, 255, 255)  # White\n",
    "        \n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            text,\n",
    "            (x_offset, y_pos),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            color,\n",
    "            1\n",
    "        )\n",
    "\n",
    "\n",
    "# MAIN DEMO FUNCTION WITH MODEL INTEGRATION\n",
    "def friend_detector_with_model(camera_index=1, model_path=\"friend_classifier.keras\"):\n",
    "    # Class names for your 8 friends\n",
    "    CLASS_NAMES = [\"Alexa\", \"Emman\", \"Enzo\", \"Joshua\", \"Migy\", \"Rafiq\", \"Vaun\", \"Zoe\"]\n",
    "    \n",
    "    # Load components\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸš€ FRIEND DETECTOR - Phase 4: Model Integration\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load face detector\n",
    "    face_cascade = load_face_detector()\n",
    "    if face_cascade is None:\n",
    "        return\n",
    "    \n",
    "    # Load model\n",
    "    model = load_trained_model(model_path)\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    # Setup output folder\n",
    "    output_folder = create_output_folder(\"CV_Predictions\")\n",
    "    \n",
    "    # Open camera\n",
    "    cap = cv2.VideoCapture(camera_index, cv2.CAP_AVFOUNDATION)\n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ Failed to open camera\")\n",
    "        return\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Controls:\")\n",
    "    print(\"   q - Quit\")\n",
    "    print(\"   s - Save prediction\")\n",
    "    print(\"   t - Toggle top predictions display\")\n",
    "    print(\"   c - Cycle confidence threshold\")\n",
    "    print(\"\\nWindow opening...\\n\")\n",
    "    \n",
    "    # State variables\n",
    "    show_top_predictions = True\n",
    "    confidence_thresholds = [0.3, 0.5, 0.7]\n",
    "    current_threshold_idx = 0\n",
    "    confidence_threshold = confidence_thresholds[current_threshold_idx]\n",
    "    \n",
    "    saved_count = 0\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = detect_faces(frame, face_cascade)\n",
    "        \n",
    "        # Process each detected face\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            # Crop and preprocess face\n",
    "            face_crop, actual_coords = crop_face(frame, (x, y, w, h), margin=20)\n",
    "            \n",
    "            if face_crop.size == 0:\n",
    "                continue\n",
    "            \n",
    "            # Preprocess for model\n",
    "            face_processed, face_display = preprocess_face_for_model(\n",
    "                face_crop,\n",
    "                target_size=(128, 128),\n",
    "                normalize=True\n",
    "            )\n",
    "            \n",
    "            # Make prediction\n",
    "            predicted_name, confidence, all_predictions = predict_friend(\n",
    "                model,\n",
    "                face_processed,\n",
    "                CLASS_NAMES,\n",
    "                confidence_threshold=confidence_threshold\n",
    "            )\n",
    "            \n",
    "            # Draw prediction box\n",
    "            draw_prediction_box(frame, (x, y, w, h), predicted_name, confidence)\n",
    "            \n",
    "            # Display preprocessed face in corner (only for first face)\n",
    "            if i == 0:\n",
    "                corner_size = 150\n",
    "                face_corner = cv2.resize(\n",
    "                    cv2.cvtColor(face_display, cv2.COLOR_RGB2BGR),\n",
    "                    (corner_size, corner_size)\n",
    "                )\n",
    "                \n",
    "                # Position in top-right corner\n",
    "                frame[10:10+corner_size, frame.shape[1]-corner_size-10:frame.shape[1]-10] = face_corner\n",
    "                \n",
    "                # Add border\n",
    "                cv2.rectangle(\n",
    "                    frame,\n",
    "                    (frame.shape[1]-corner_size-10, 10),\n",
    "                    (frame.shape[1]-10, 10+corner_size),\n",
    "                    (255, 255, 0),\n",
    "                    2\n",
    "                )\n",
    "                \n",
    "                # Show top predictions if enabled\n",
    "                if show_top_predictions:\n",
    "                    display_top_predictions(frame, all_predictions)\n",
    "        \n",
    "        # Add overlay info\n",
    "        fps = frame_count / (time.time() - start_time)\n",
    "        \n",
    "        cv2.putText(frame, f\"FPS: {fps:.1f}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame, f\"Faces: {len(faces)}\", (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame, f\"Threshold: {confidence_threshold:.1f}\", (10, 90),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Controls help\n",
    "        cv2.putText(frame, \"q: Quit | s: Save | t: Toggle | c: Threshold\",\n",
    "                   (10, frame.shape[0]-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Display\n",
    "        cv2.imshow('Friend Detector - Phase 4: COMPLETE!', frame)\n",
    "        \n",
    "        # Handle input\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        \n",
    "        elif key == ord('s') and len(faces) > 0:\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = output_folder / f\"prediction_{predicted_name}_{timestamp}.jpg\"\n",
    "            cv2.imwrite(str(filename), frame)\n",
    "            saved_count += 1\n",
    "            print(f\"ğŸ’¾ Saved: {filename}\")\n",
    "        \n",
    "        elif key == ord('t'):\n",
    "            show_top_predictions = not show_top_predictions\n",
    "            print(f\"ğŸ“Š Top predictions: {'ON' if show_top_predictions else 'OFF'}\")\n",
    "        \n",
    "        elif key == ord('c'):\n",
    "            current_threshold_idx = (current_threshold_idx + 1) % len(confidence_thresholds)\n",
    "            confidence_threshold = confidence_thresholds[current_threshold_idx]\n",
    "            print(f\"ğŸ¯ Confidence threshold: {confidence_threshold:.1f}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"\\nâœ… Session complete! Saved {saved_count} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35c03fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸš€ FRIEND DETECTOR - Phase 4: Model Integration\n",
      "============================================================\n",
      "âœ… Face detector loaded successfully!\n",
      "ğŸ”„ Loading model from Models/friend_classifier.keras...\n",
      "âœ… Model loaded successfully!\n",
      "\n",
      "ğŸ“Š Model Summary:\n",
      "   Input shape: (None, 128, 128, 3)\n",
      "   Output shape: (None, 8)\n",
      "   Total parameters: 1,072,744\n",
      "ğŸ“ Output folder ready: /Users/enzobasuil/Desktop/Coding Projects/Python Projects/FriendIdentifier/CV_Predictions\n",
      "\n",
      "ğŸ“‹ Controls:\n",
      "   q - Quit\n",
      "   s - Save prediction\n",
      "   t - Toggle top predictions display\n",
      "   c - Cycle confidence threshold\n",
      "\n",
      "Window opening...\n",
      "\n",
      "ğŸ“Š Top predictions: OFF\n",
      "ğŸ“Š Top predictions: ON\n",
      "ğŸ’¾ Saved: CV_Predictions/prediction_Unknown_20251103_140150.jpg\n",
      "ğŸ’¾ Saved: CV_Predictions/prediction_Zoe_20251103_140243.jpg\n",
      "ğŸ’¾ Saved: CV_Predictions/prediction_Zoe_20251103_140245.jpg\n",
      "ğŸ’¾ Saved: CV_Predictions/prediction_Alexa_20251103_140255.jpg\n",
      "ğŸ’¾ Saved: CV_Predictions/prediction_Alexa_20251103_140256.jpg\n",
      "ğŸ’¾ Saved: CV_Predictions/prediction_Alexa_20251103_140609.jpg\n",
      "ğŸ’¾ Saved: CV_Predictions/prediction_Alexa_20251103_140610.jpg\n",
      "\n",
      "âœ… Session complete! Saved 7 predictions\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Run Phase 4: Complete Friend Detector with Model\n",
    "    friend_detector_with_model(\n",
    "        camera_index=1,\n",
    "        model_path=\"Models/friend_classifier.keras\"  # Make sure this file is in your directory!\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
