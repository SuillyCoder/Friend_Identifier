{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5ad9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0e16982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Directory for OpenCV screenshots\n",
    "screenshot_dir = 'CV_Screenshots'\n",
    "os.makedirs(screenshot_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a08de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PHASE 1: CAMERA ACCESS AND SETUP\n",
    "\n",
    "def find_working_camera():\n",
    "    print(\"ğŸ” Searching for working camera...\\n\")\n",
    "    \n",
    "    # Try with AVFoundation (Mac-specific)\n",
    "    cap = cv2.VideoCapture(1, cv2.CAP_AVFOUNDATION)\n",
    "        \n",
    "    if cap.isOpened():\n",
    "            # Try to read a frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret and frame is not None:\n",
    "            h, w = frame.shape[:2]\n",
    "            print(f\"âœ… WORKS! ({w}x{h})\")\n",
    "            cap.release()\n",
    "            return 1\n",
    "        else:\n",
    "            print(\"âŒ Opens but can't grab frames\")\n",
    "    else:\n",
    "        print(\"âŒ Can't open\")\n",
    "        \n",
    "    cap.release()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfd935cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_camera_access():\n",
    "    # Find working camera\n",
    "    camera_index = find_working_camera()\n",
    "    \n",
    "    if camera_index is None:\n",
    "        print(\"\\nâŒ ERROR: No working camera found!\")\n",
    "        print(\"ğŸ’¡ Troubleshooting:\")\n",
    "        print(\"   1. Close any apps using camera (Zoom, Teams, FaceTime)\")\n",
    "        print(\"   2. System Settings > Privacy & Security > Camera\")\n",
    "        print(\"      â†’ Enable for Terminal/Python/VS Code\")\n",
    "        print(\"   3. Restart your Python kernel/terminal\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nâœ… Using camera {camera_index}\")\n",
    "    \n",
    "    # Open camera with AVFoundation backend (better for Mac)\n",
    "    cap = cv2.VideoCapture(camera_index, cv2.CAP_AVFOUNDATION)\n",
    "    \n",
    "    # Force better settings\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "    \n",
    "    print(\"âœ… Camera opened successfully!\")\n",
    "    print(\"\\nğŸ“‹ Instructions:\")\n",
    "    print(\"   - Press 'q' to quit\")\n",
    "    print(\"   - Press 's' to save screenshot\")\n",
    "    print(\"   - ESC also quits\")\n",
    "    print(\"\\nCamera window should open now...\\n\")\n",
    "    \n",
    "    # Get camera properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    print(f\"ğŸ“Š Camera Info:\")\n",
    "    print(f\"   Resolution: {width}x{height}\")\n",
    "    print(f\"   FPS: {fps}\")\n",
    "    \n",
    "    screenshot_count = 0\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Main camera loop\n",
    "    while True:\n",
    "        # Read frame from camera\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"âŒ Failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Calculate actual FPS\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > 0:\n",
    "            actual_fps = frame_count / elapsed_time\n",
    "        else:\n",
    "            actual_fps = 0\n",
    "        \n",
    "        # Add FPS counter to frame\n",
    "        cv2.putText(\n",
    "            frame, \n",
    "            f\"FPS: {actual_fps:.1f}\", \n",
    "            (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            0.7, \n",
    "            (0, 255, 0), \n",
    "            2\n",
    "        )\n",
    "        \n",
    "        # Add instructions\n",
    "        cv2.putText(\n",
    "            frame, \n",
    "            \"Press 'q' to quit, 's' for screenshot\", \n",
    "            (10, height - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            0.5, \n",
    "            (255, 255, 255), \n",
    "            1\n",
    "        )\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('Friend Classifier - Phase 1', frame)\n",
    "        \n",
    "        # Handle keyboard input\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q') or key == 27:  # 'q' or ESC\n",
    "            print(\"\\nğŸ‘‹ Quitting...\")\n",
    "            break\n",
    "        elif key == ord('s'):  # Save screenshot\n",
    "            screenshot_count += 1\n",
    "            filename = os.path.join(screenshot_dir, f'screenshot_{screenshot_count}.jpg')\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"ğŸ“¸ Screenshot saved: {filename}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… PHASE 1 COMPLETE!\")\n",
    "    print(f\"   Total frames: {frame_count}\")\n",
    "    print(f\"   Average FPS: {actual_fps:.1f}\")\n",
    "    print(f\"   Screenshots: {screenshot_count}\")\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7236b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PHASE 2: FACE DETECTION\n",
    "# ============================================\n",
    "\n",
    "def load_face_detector():\n",
    "    \"\"\"\n",
    "    Load the Haar Cascade face detector.\n",
    "    \n",
    "    Returns:\n",
    "        face_cascade: OpenCV cascade classifier for face detection\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ“¦ Loading Haar Cascade face detector...\")\n",
    "    \n",
    "    cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "    face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "    \n",
    "    if face_cascade.empty():\n",
    "        print(\"âŒ ERROR: Could not load face detector!\")\n",
    "        print(f\"   Tried path: {cascade_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(\"âœ… Face detector loaded successfully!\")\n",
    "    return face_cascade\n",
    "\n",
    "\n",
    "def detect_faces(frame, face_cascade, scale_factor=1.1, min_neighbors=5, min_size=(30, 30)):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=scale_factor,\n",
    "        minNeighbors=min_neighbors,\n",
    "        minSize=min_size,\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9046476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "    â•‘                                                          â•‘\n",
      "    â•‘         FRIEND FACE CLASSIFIER - CAMERA SYSTEM          â•‘\n",
      "    â•‘            Phase 2+3: Detection & Preprocessing          â•‘\n",
      "    â•‘                                                          â•‘\n",
      "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "    \n",
      "\n",
      "============================================================\n",
      "ğŸ”ª PHASE 2+3: FACE DETECTION & PREPROCESSING\n",
      "============================================================\n",
      "ğŸ“¦ Loading Haar Cascade face detector...\n",
      "âœ… Face detector loaded successfully!\n",
      "ğŸ“ Output folder ready: /Users/enzobasuil/Desktop/Coding Projects/Python Projects/FriendIdentifier/CV_PrePrep_Faces\n",
      "\n",
      "ğŸ“‹ Controls:\n",
      "   q - Quit\n",
      "   s - Save preprocessed face\n",
      "   v - Visualize preprocessing steps\n",
      "   d - Toggle debug info\n",
      "\n",
      "Window opening...\n",
      "\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ’¾ Saved: CV_PrePrep_Faces/face_20251103_12174.jpg\n",
      "ğŸ’¾ Saved: CV_PrePrep_Faces/face_20251103_12174.jpg\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ’¾ Saved: CV_PrePrep_Faces/face_20251103_12181.jpg\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ’¾ Saved: CV_PrePrep_Faces/face_20251103_12182.jpg\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ’¾ Saved: CV_PrePrep_Faces/face_20251103_12182.jpg\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ’¾ Saved: CV_PrePrep_Faces/face_20251103_12185.jpg\n",
      "ğŸ“Š Preprocessing visualization opened (close window to continue)\n",
      "ğŸ’¾ Saved: CV_PrePrep_Faces/face_20251103_12185.jpg\n",
      "\n",
      "============================================================\n",
      "âœ… PHASE 2+3 COMPLETE!\n",
      "   Frames processed: 2086\n",
      "   Faces saved: 7\n",
      "   Output folder: /Users/enzobasuil/Desktop/Coding Projects/Python Projects/FriendIdentifier/CV_PrePrep_Faces\n",
      "============================================================\n",
      "\n",
      "ğŸ‰ Phase 2+3 Complete!\n",
      "\n",
      "What you learned:\n",
      "  âœ… How to detect faces with Haar Cascades\n",
      "  âœ… How to crop faces from frames\n",
      "  âœ… How to resize to model's expected size\n",
      "  âœ… How to normalize pixel values (0-1 range)\n",
      "  âœ… How to convert BGR â†’ RGB\n",
      "  âœ… How to add batch dimension\n",
      "\n",
      "Next steps:\n",
      "  âœ… Phase 1: Camera access\n",
      "  âœ… Phase 2: Face detection\n",
      "  âœ… Phase 3: Face preprocessing (DONE!)\n",
      "  â­ï¸  Phase 4: Load model & classify\n",
      "  â­ï¸  Phase 5: Final integration & polish\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# PHASE 3: FACE PREPROCESSING\n",
    "# ============================================\n",
    "\n",
    "def create_output_folder(folder_name=\"CV_PrePrep_Faces\"):\n",
    "    folder_path = Path(folder_name)\n",
    "    folder_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"ğŸ“ Output folder ready: {folder_path.absolute()}\")\n",
    "    \n",
    "    return folder_path\n",
    "\n",
    "\n",
    "def crop_face(frame, face_coords, margin=20): \n",
    "    x, y, w, h = face_coords\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    \n",
    "    # Add margin but stay within frame bounds\n",
    "    x1 = max(0, x - margin)\n",
    "    y1 = max(0, y - margin)\n",
    "    x2 = min(frame_width, x + w + margin)\n",
    "    y2 = min(frame_height, y + h + margin)\n",
    "    \n",
    "    # Crop the face\n",
    "    face_crop = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    actual_coords = (x1, y1, x2-x1, y2-y1)\n",
    "    \n",
    "    return face_crop, actual_coords\n",
    "\n",
    "\n",
    "def preprocess_face_for_model(face_crop, target_size=(128, 128), normalize=True):\n",
    "    \"\"\"\n",
    "    Preprocess a cropped face for model prediction.\n",
    "    This MUST match your training preprocessing!\n",
    "    \n",
    "    Steps:\n",
    "        1. Convert BGR (OpenCV) to RGB (model format)\n",
    "        2. Resize to model's expected input size\n",
    "        3. Normalize pixel values to 0-1 range\n",
    "        4. Add batch dimension\n",
    "    \n",
    "    Args:\n",
    "        face_crop: Cropped face image (BGR from OpenCV)\n",
    "        target_size: Size your model expects (default: 128x128)\n",
    "        normalize: Whether to normalize to 0-1 range (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        processed_face: Face ready for model.predict()\n",
    "        display_face: Face for visualization (RGB, not normalized)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Convert BGR to RGB (OpenCV uses BGR, model expects RGB)\n",
    "    face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Step 2: Resize to model's expected input size\n",
    "    face_resized = cv2.resize(face_rgb, target_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Step 3: Create display version (before normalization)\n",
    "    display_face = face_resized.copy()\n",
    "    \n",
    "    # Step 4: Normalize pixel values to 0-1 range (if needed)\n",
    "    if normalize:\n",
    "        face_normalized = face_resized.astype(np.float32) / 255.0\n",
    "    else:\n",
    "        face_normalized = face_resized.astype(np.float32)\n",
    "    \n",
    "    # Step 5: Add batch dimension (model expects: batch_size, height, width, channels)\n",
    "    face_batched = np.expand_dims(face_normalized, axis=0)\n",
    "    \n",
    "    return face_batched, display_face\n",
    "\n",
    "\n",
    "def save_preprocessed_face(face_image, folder_path, prefix=\"face\", timestamp=None):\n",
    "    \"\"\"\n",
    "    Save a preprocessed face to disk.\n",
    "    \n",
    "    Args:\n",
    "        face_image: Face image to save (RGB or BGR)\n",
    "        folder_path: Path object to save folder\n",
    "        prefix: Filename prefix\n",
    "        timestamp: Optional timestamp for unique filename\n",
    "    \n",
    "    Returns:\n",
    "        filename: Path to saved file\n",
    "    \"\"\"\n",
    "    \n",
    "    if timestamp is None:\n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Generate unique filename\n",
    "    filename = folder_path / f\"{prefix}_{timestamp}.jpg\"\n",
    "    \n",
    "    # Convert RGB to BGR for saving (OpenCV saves in BGR)\n",
    "    if face_image.dtype == np.float32:\n",
    "        # If normalized, denormalize first\n",
    "        face_image = (face_image * 255).astype(np.uint8)\n",
    "    \n",
    "    face_bgr = cv2.cvtColor(face_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Save\n",
    "    cv2.imwrite(str(filename), face_bgr)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "\n",
    "def visualize_preprocessing_pipeline(face_crop, target_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Show each preprocessing step side-by-side.\n",
    "    Useful for understanding what happens to the image.\n",
    "    \n",
    "    Args:\n",
    "        face_crop: Original cropped face\n",
    "        target_size: Target size for model\n",
    "    \n",
    "    Returns:\n",
    "        combined: Visualization showing all 4 steps\n",
    "    \"\"\"\n",
    "    \n",
    "    # Original (BGR)\n",
    "    step1 = face_crop\n",
    "    \n",
    "    # Convert to RGB\n",
    "    step2 = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize\n",
    "    step3 = cv2.resize(step2, target_size)\n",
    "    \n",
    "    # Normalize (for visualization, convert back to 0-255)\n",
    "    step4_normalized = step3.astype(np.float32) / 255.0\n",
    "    step4 = (step4_normalized * 255).astype(np.uint8)\n",
    "    \n",
    "    # Create visualization\n",
    "    h, w = 200, 200\n",
    "    \n",
    "    # Resize all to same size for display\n",
    "    display1 = cv2.resize(step1, (w, h))\n",
    "    display2 = cv2.resize(cv2.cvtColor(step2, cv2.COLOR_RGB2BGR), (w, h))\n",
    "    display3 = cv2.resize(cv2.cvtColor(step3, cv2.COLOR_RGB2BGR), (w, h))\n",
    "    display4 = cv2.resize(cv2.cvtColor(step4, cv2.COLOR_RGB2BGR), (w, h))\n",
    "    \n",
    "    # Add labels\n",
    "    def add_label(img, text):\n",
    "        labeled = img.copy()\n",
    "        cv2.putText(labeled, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   0.7, (0, 255, 0), 2)\n",
    "        return labeled\n",
    "    \n",
    "    display1 = add_label(display1, \"1. Original\")\n",
    "    display2 = add_label(display2, \"2. BGR->RGB\")\n",
    "    display3 = add_label(display3, f\"3. Resize {target_size}\")\n",
    "    display4 = add_label(display4, \"4. Normalized\")\n",
    "    \n",
    "    # Combine horizontally\n",
    "    top_row = np.hstack([display1, display2])\n",
    "    bottom_row = np.hstack([display3, display4])\n",
    "    combined = np.vstack([top_row, bottom_row])\n",
    "    \n",
    "    return combined\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# MAIN DEMO FUNCTION\n",
    "# ============================================\n",
    "\n",
    "def face_preprocessing_demo(camera_index=1):\n",
    "    \"\"\"\n",
    "    Interactive demo showing face preprocessing in real-time.\n",
    "    \n",
    "    Controls:\n",
    "        - Press 'q' to quit\n",
    "        - Press 's' to save preprocessed face\n",
    "        - Press 'v' to show preprocessing steps\n",
    "        - Press 'd' to toggle debug info\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ”ª PHASE 2+3: FACE DETECTION & PREPROCESSING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Setup\n",
    "    face_cascade = load_face_detector()\n",
    "    if face_cascade is None:\n",
    "        return\n",
    "    \n",
    "    output_folder = create_output_folder(\"CV_PrePrep_Faces\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(camera_index, cv2.CAP_AVFOUNDATION)\n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ Failed to open camera\")\n",
    "        return\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Controls:\")\n",
    "    print(\"   q - Quit\")\n",
    "    print(\"   s - Save preprocessed face\")\n",
    "    print(\"   v - Visualize preprocessing steps\")\n",
    "    print(\"   d - Toggle debug info\")\n",
    "    print(\"\\nWindow opening...\\n\")\n",
    "    \n",
    "    # State\n",
    "    show_debug = True\n",
    "    saved_count = 0\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = detect_faces(frame, face_cascade)\n",
    "        \n",
    "        # Process each detected face\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            # Draw detection box\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Crop face\n",
    "            face_crop, _ = crop_face(frame, (x, y, w, h), margin=20)\n",
    "            \n",
    "            if face_crop.size == 0:\n",
    "                continue\n",
    "            \n",
    "            # Preprocess for model\n",
    "            face_processed, face_display = preprocess_face_for_model(\n",
    "                face_crop, \n",
    "                target_size=(128, 128)\n",
    "            )\n",
    "            \n",
    "            # Display preprocessed face in corner\n",
    "            corner_size = 150\n",
    "            face_corner = cv2.resize(\n",
    "                cv2.cvtColor(face_display, cv2.COLOR_RGB2BGR),\n",
    "                (corner_size, corner_size)\n",
    "            )\n",
    "            \n",
    "            # Position in top-right corner\n",
    "            frame[10:10+corner_size, frame.shape[1]-corner_size-10:frame.shape[1]-10] = face_corner\n",
    "            \n",
    "            # Add border around preview\n",
    "            cv2.rectangle(\n",
    "                frame,\n",
    "                (frame.shape[1]-corner_size-10, 10),\n",
    "                (frame.shape[1]-10, 10+corner_size),\n",
    "                (255, 255, 0),\n",
    "                2\n",
    "            )\n",
    "            \n",
    "            # Show preprocessing info\n",
    "            if show_debug:\n",
    "                info_x = x\n",
    "                info_y = y - 10\n",
    "                \n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    f\"Face {i+1}\",\n",
    "                    (info_x, info_y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6,\n",
    "                    (0, 255, 0),\n",
    "                    2\n",
    "                )\n",
    "                \n",
    "                # Show dimensions\n",
    "                debug_text = [\n",
    "                    f\"Original: {face_crop.shape[1]}x{face_crop.shape[0]}\",\n",
    "                    f\"Processed: 128x128\",\n",
    "                    f\"Shape: {face_processed.shape}\",\n",
    "                    f\"Range: [0.0, 1.0]\"\n",
    "                ]\n",
    "                \n",
    "                for j, text in enumerate(debug_text):\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        text,\n",
    "                        (info_x, y + h + 20 + j*20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.4,\n",
    "                        (255, 255, 255),\n",
    "                        1\n",
    "                    )\n",
    "        \n",
    "        # Add overlay info\n",
    "        fps = frame_count / (time.time() - start_time)\n",
    "        \n",
    "        cv2.putText(frame, f\"FPS: {fps:.1f}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame, f\"Faces: {len(faces)}\", (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame, f\"Saved: {saved_count}\", (10, 90),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame, \"Preview (preprocessed)\", \n",
    "                   (frame.shape[1]-240, frame.shape[0]-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)\n",
    "        \n",
    "        cv2.putText(frame, \"q: Quit | s: Save | v: Visualize | d: Debug\",\n",
    "                   (10, frame.shape[0]-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Display\n",
    "        cv2.imshow('Phase 2+3: Detection & Preprocessing', frame)\n",
    "        \n",
    "        # Handle input\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        \n",
    "        elif key == ord('s') and len(faces) > 0:\n",
    "            # Save first detected face\n",
    "            face_crop, _ = crop_face(frame, faces[0], margin=20)\n",
    "            _, face_display = preprocess_face_for_model(face_crop)\n",
    "            \n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S_%f\")[:-3]\n",
    "            filename = save_preprocessed_face(face_display, output_folder, timestamp=timestamp)\n",
    "            \n",
    "            saved_count += 1\n",
    "            print(f\"ğŸ’¾ Saved: {filename}\")\n",
    "        \n",
    "        elif key == ord('v') and len(faces) > 0:\n",
    "            # Show preprocessing visualization\n",
    "            face_crop, _ = crop_face(frame, faces[0], margin=20)\n",
    "            vis = visualize_preprocessing_pipeline(face_crop)\n",
    "            \n",
    "            cv2.imshow('Preprocessing Steps', vis)\n",
    "            print(\"ğŸ“Š Preprocessing visualization opened (close window to continue)\")\n",
    "        \n",
    "        elif key == ord('d'):\n",
    "            show_debug = not show_debug\n",
    "            print(f\"ğŸ› Debug info: {'ON' if show_debug else 'OFF'}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… PHASE 2+3 COMPLETE!\")\n",
    "    print(f\"   Frames processed: {frame_count}\")\n",
    "    print(f\"   Faces saved: {saved_count}\")\n",
    "    print(f\"   Output folder: {output_folder.absolute()}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# USAGE\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"\"\"\n",
    "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    â•‘                                                          â•‘\n",
    "    â•‘         FRIEND FACE CLASSIFIER - CAMERA SYSTEM          â•‘\n",
    "    â•‘            Phase 2+3: Detection & Preprocessing          â•‘\n",
    "    â•‘                                                          â•‘\n",
    "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \"\"\")\n",
    "    \n",
    "    # Run the demo\n",
    "    face_preprocessing_demo(camera_index=1)\n",
    "    \n",
    "    print(\"\\nğŸ‰ Phase 2+3 Complete!\")\n",
    "    print(\"\\nWhat you learned:\")\n",
    "    print(\"  âœ… How to detect faces with Haar Cascades\")\n",
    "    print(\"  âœ… How to crop faces from frames\")\n",
    "    print(\"  âœ… How to resize to model's expected size\")\n",
    "    print(\"  âœ… How to normalize pixel values (0-1 range)\")\n",
    "    print(\"  âœ… How to convert BGR â†’ RGB\")\n",
    "    print(\"  âœ… How to add batch dimension\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  âœ… Phase 1: Camera access\")\n",
    "    print(\"  âœ… Phase 2: Face detection\")\n",
    "    print(\"  âœ… Phase 3: Face preprocessing (DONE!)\")\n",
    "    print(\"  â­ï¸  Phase 4: Load model & classify\")\n",
    "    print(\"  â­ï¸  Phase 5: Final integration & polish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
